{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ee1a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, current_timestamp, col, when, collect_list, sha2, concat_ws, collect_set,udf,monotonically_increasing_id\n",
    "from pydeequ.verification import *\n",
    "import pydeequ\n",
    "from pydeequ.checks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b35d39d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\\\n",
    "    .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f08370",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = spark.read.format('csv').load(r'..\\data\\merchant.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce093df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------------+-----------+--------------------+--------------------+\n",
      "|merchant_id|        company_name|  contact_no|      state|          created_at|          updated_at|\n",
      "+-----------+--------------------+------------+-----------+--------------------+--------------------+\n",
      "|     178307|            MSI Kart|  9319919988|trial_ended|2021-01-02 09:33:...|2021-01-02 09:39:...|\n",
      "|     177863|  Bellelyse Boutique|000-000-0000|  suspended|2020-12-31 04:56:...|2021-02-19 16:53:...|\n",
      "|     144524|     Rachid hamzaoui|  0639756718|       free|2020-09-21 17:18:...|2020-10-22 11:15:...|\n",
      "|      50742|Thenaricalicollec...|  5049394269|  suspended|2019-03-22 03:57:...|2019-05-15 00:54:...|\n",
      "|     176321|   CLICK MY CART LTD|  6479863690|  suspended|2020-12-23 06:20:...|2020-12-24 04:53:...|\n",
      "|     140294|              myself|  7149259700|       free|2020-09-05 17:41:...|2020-10-06 11:15:...|\n",
      "|     165163|  JeeJeeâ€™s Boutique |208-202-9314|trial_ended|2020-11-20 16:31:...|2020-11-20 16:33:...|\n",
      "|     156237|     Only The Flyest|  4049038447|       free|2020-10-27 05:26:...|2020-11-26 11:15:...|\n",
      "|     156237|          Washer Fan|000-000-0000|provisioned|2020-10-26 20:10:...|2020-10-26 20:53:...|\n",
      "|       null|Quick Draw Outdoo...|  3182596422|provisioned|2019-02-04 16:57:...|2021-02-10 02:07:...|\n",
      "+-----------+--------------------+------------+-----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c821b15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----+-----+\n",
      "| entity|instance|name|value|\n",
      "+-------+--------+----+-----+\n",
      "|Dataset|       *|Size| 10.0|\n",
      "+-------+--------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysisResult = AnalysisRunner(spark) \\\n",
    "                    .onData(dataframe) \\\n",
    "                    .addAnalyzer(Size()) \\\n",
    "                    .run()\n",
    "                    \n",
    "analysisResult_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult)\n",
    "analysisResult_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7855e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = Check(spark, CheckLevel.Error, \"Sellbrite checks\")\n",
    "\n",
    "Verifying_Checks = (VerificationSuite(spark)\n",
    "    .onData(dataframe)\n",
    "    .addCheck(check.isComplete('merchant_id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dfcf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b7bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.isComplete('merchant_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a20233",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pydeequ_Check_Verification:\n",
    "\n",
    "    def check_fileformat_generate_dataset(self, sections):\n",
    "        dataframe = spark.read.format('csv').load(r'..\\data\\merchant.csv',header=True,inferSchema=True)\n",
    "        dataframe.show(truncate=False)\n",
    "        check_result_dataframe = self.verify_checks_on_datasets(dataframe, sections)\n",
    "        return check_result_dataframe\n",
    "\n",
    "    def verify_checks_on_datasets(self, tables, datasets):\n",
    "        dataset_id = config_df.filter(config_df.Table_name == datasets).select('dataset_id').first()[0]\n",
    "        checker = config_df.filter(config_df.Table_name == datasets).select(collect_list('check')).first()[0]\n",
    "        dq_verification_config_id = config_df.filter(config_df.Table_name == datasets).select(collect_list('dq_verification_config_id')).first()[0]\n",
    "        \n",
    "        check = Check(spark, CheckLevel.Error, \"Sellbrite checks\")\n",
    "        checker.insert(0, \"check\")\n",
    "        checks = \"\".join(checker)\n",
    "\n",
    "        Verifying_Checks = (VerificationSuite(spark)\n",
    "                            .onData(tables)\n",
    "                            .addCheck(eval(checks))\n",
    "                            .run())\n",
    "                            \n",
    "        Check_Reports = VerificationResult.checkResultsAsDataFrame(spark, Verifying_Checks)\n",
    "        VerificationResult.successMetricsAsDataFrame(spark, Verifying_Checks).show()\n",
    "        Check_Reports = Check_Reports.repartition(1).withColumn(\"dq_verification_config_id\", udf(lambda id: dq_verification_config_id[id])(monotonically_increasing_id()))\n",
    "        Check_Reports.show()\n",
    "        \n",
    "        Check_Reports_Dataframe = (Check_Reports.withColumn('create_utc_ts', lit(current_timestamp()))\n",
    "                                   .withColumn('dataset_id', lit(dataset_id)))\n",
    "                                   \n",
    "        Check_Reports_Dataframe = Check_Reports_Dataframe.join(config_df, Check_Reports_Dataframe.dq_verification_config_id == config_df.dq_verification_config_id).select(Check_Reports_Dataframe['*'], config_df.br_identification_required)\n",
    "\n",
    "        Check_Reports_Dataframe = Check_Reports_Dataframe.withColumn('bad_record_required_flag', when((col('constraint_status') == 'Failure') & (col('br_identification_required') == 'Yes'), lit('True')).otherwise(lit('False')))\n",
    "        Check_Reports_Dataframe.show(truncate=False)\n",
    "        return VerificationResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58613500",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_config_id = {\"CompletenessConstraint(Completeness(merchant_id,None))\":1,\"UniquenessConstraint(Uniqueness(List(merchant_id),None))\":2,\"ComplianceConstraint(Compliance(merchant_id is non-negative,COALESCE(merchant_id, 0.0) >= 0,None))\":3}\n",
    "config_df = spark.read.json(r'..\\config\\dq_verification_config.json')\n",
    "config_df.show(truncate=False)\n",
    "\n",
    "\n",
    "sections = [\"merchant_cln\"]\n",
    "\n",
    "Pydeequ_Check_Verification_object = Pydeequ_Check_Verification()\n",
    "#list(map(Pydeequ_Check_Verification_object.check_fileformat_generate_dataset, sections))\n",
    "r = Pydeequ_Check_Verification_object.check_fileformat_generate_dataset(sections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cc0c8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['merchant_cln']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parser = ConfigParser()\n",
    "configFile = r\"../config/verification_config.properties\"\n",
    "Parser.read(configFile)\n",
    "Parser.sections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2adc6436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'isComplete(\"merchant_id\")|isUnique(\"merchant_id\")|isNonNegative(\"merchant_id\")'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parser.get('merchant_cln','check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f75d6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_config = spark.read.format('csv').load(r'..\\config\\verification_config.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4c63684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+--------------------+-------------+-------------+----------+------------+-------------+-----------------------------+-----------------------------+\n",
      "|dq_verification_config_id|modified_column_name|database_name|create_utc_ts|dataset_id|Table_name  |update_utc_ts|check_name                   |check                        |\n",
      "+-------------------------+--------------------+-------------+-------------+----------+------------+-------------+-----------------------------+-----------------------------+\n",
      "|1                        |null                |default      |null         |1001      |merchant_cln|null         |Sellbrite_merchant_cln_checks|.isComplete('merchant_id')   |\n",
      "|2                        |null                |default      |null         |1001      |merchant_cln|null         |Sellbrite_merchant_cln_checks|.isUnique('merchant_id')     |\n",
      "|3                        |null                |default      |null         |1001      |merchant_cln|null         |Sellbrite_merchant_cln_checks|.isNonNegative('merchant_id')|\n",
      "+-------------------------+--------------------+-------------+-------------+----------+------------+-------------+-----------------------------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verification_config.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "713d48af",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_df = spark.read.json(r'..\\config\\dq_verification_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c548ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------------+--------------------+-------------+-------------+----------+-------------------------+-------------+\n",
      "|  Table_name|br_identification_required|               check|create_utc_ts|database_name|dataset_id|dq_verification_config_id|update_utc_ts|\n",
      "+------------+--------------------------+--------------------+-------------+-------------+----------+-------------------------+-------------+\n",
      "|merchant_cln|                        No|.isUnique(\"mercha...|             |      default|      1001|                        1|             |\n",
      "|merchant_cln|                       Yes|.isComplete(\"merc...|             |      default|      1001|                        2|             |\n",
      "|    user_cln|                        No|     .isUnique(\"id\")|             |      default|      1002|                        3|             |\n",
      "|    user_cln|                       Yes|   .isComplete(\"id\")|             |      default|      1002|                        4|             |\n",
      "+------------+--------------------------+--------------------+-------------+-------------+----------+-------------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d0cc56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['merchant_cln', 'user_cln']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_df.select('Table_name').distinct().select(collect_list('Table_name')).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "497be332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_cln', 'merchant_cln']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_df.select(collect_set('Table_name')).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01977932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_df.filter(col('Table_name')=='merchant_cln').select('database_name').first()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
