{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, current_timestamp\n",
    "from configparser import ConfigParser\n",
    "import pydeequ\n",
    "from pydeequ.checks import *\n",
    "from pydeequ.verification import *\n",
    "from pydeequ.analyzers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\config\\\\checks.json']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parser = ConfigParser()\n",
    "configFile = r\"..\\config\\checks.json\"\n",
    "Parser.read(configFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.jars\", \"C:\\Program Files (x86)\\PostgreSQL\\pgJDBC\\postgresql-42.2.18.jar\") \\\n",
    "    .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\\\n",
    "    .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets_verify_constrains(sections):\n",
    "    if Parser.get(sections,\"file_format\")==\"csv\":\n",
    "        tables = (spark.read.format('csv').options(header=True,inferSchema=True).load(Parser.get(sections, 'source')))\n",
    "    elif Parser.get(sections,\"file_format\")==\"parquet\":\n",
    "        tables = (spark.read.parquet(Parser.get(sections,'source')))\n",
    "    \n",
    "    #tables = (spark.read.format(Parser.get(sections,'file_format')).options(header=True,inferSchema=True).load(Parser.get(sections,'source')))\n",
    "    print(sections)\n",
    "    #tables.show()\n",
    "    checker = Parser.get(sections,'checks').split(',')\n",
    "    checker.insert(0,\"check\")\n",
    "    checks =\".\".join(checker)\n",
    "    check = Check(spark, CheckLevel.Error, Parser.get(sections,'check_name'))\n",
    "    checkResult = (VerificationSuite(spark)\n",
    "                   .onData(tables)\n",
    "                   .addCheck(eval(checks))\n",
    "                   .run())\n",
    "    checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "    checkResult_df_result = (checkResult_df.withColumn('dataset_name',lit(sections))\n",
    "                         .withColumn('check_run_tsp',lit(current_timestamp())))\n",
    "    checkResult_df_result.show()\n",
    "    checks_result_path = str(Parser.get(sections, 'checks_result')) + sections\n",
    "    checkResult_df_result.coalesce(1).write.csv(f'{checks_result_path}',header=True,mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sellbrite checks'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parser.get(\"merchants\", 'check_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merchants\n",
      "+----------------+-----------+------------+--------------------+-----------------+------------------+------------+--------------------+\n",
      "|           check|check_level|check_status|          constraint|constraint_status|constraint_message|dataset_name|       check_run_tsp|\n",
      "+----------------+-----------+------------+--------------------+-----------------+------------------+------------+--------------------+\n",
      "|Sellbrite checks|      Error|     Success|CompletenessConst...|          Success|                  |   merchants|2020-12-30 20:10:...|\n",
      "|Sellbrite checks|      Error|     Success|UniquenessConstra...|          Success|                  |   merchants|2020-12-30 20:10:...|\n",
      "|Sellbrite checks|      Error|     Success|ComplianceConstra...|          Success|                  |   merchants|2020-12-30 20:10:...|\n",
      "+----------------+-----------+------------+--------------------+-----------------+------------------+------------+--------------------+\n",
      "\n",
      "users\n",
      "+----------------+-----------+------------+--------------------+-----------------+------------------+------------+--------------------+\n",
      "|           check|check_level|check_status|          constraint|constraint_status|constraint_message|dataset_name|       check_run_tsp|\n",
      "+----------------+-----------+------------+--------------------+-----------------+------------------+------------+--------------------+\n",
      "|Sellbrite checks|      Error|     Success|CompletenessConst...|          Success|                  |       users|2020-12-30 20:10:...|\n",
      "|Sellbrite checks|      Error|     Success|UniquenessConstra...|          Success|                  |       users|2020-12-30 20:10:...|\n",
      "|Sellbrite checks|      Error|     Success|ComplianceConstra...|          Success|                  |       users|2020-12-30 20:10:...|\n",
      "+----------------+-----------+------------+--------------------+-----------------+------------------+------------+--------------------+\n",
      "\n",
      "orders\n",
      "+----------------+-----------+------------+--------------------+-----------------+------------------+------------+--------------------+\n",
      "|           check|check_level|check_status|          constraint|constraint_status|constraint_message|dataset_name|       check_run_tsp|\n",
      "+----------------+-----------+------------+--------------------+-----------------+------------------+------------+--------------------+\n",
      "|Sellbrite checks|      Error|     Success|CompletenessConst...|          Success|                  |      orders|2020-12-30 20:10:...|\n",
      "|Sellbrite checks|      Error|     Success|UniquenessConstra...|          Success|                  |      orders|2020-12-30 20:10:...|\n",
      "|Sellbrite checks|      Error|     Success|ComplianceConstra...|          Success|                  |      orders|2020-12-30 20:10:...|\n",
      "+----------------+-----------+------------+--------------------+-----------------+------------------+------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(get_datasets_verify_constrains,Parser.sections()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
